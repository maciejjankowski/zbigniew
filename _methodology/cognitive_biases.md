# COGNITIVE BIASES IN INTELLIGENCE ANALYSIS

*Your brain is lying to you. Here's how.*

---

## THE PROBLEM

Human cognition evolved for survival, not accuracy. The same shortcuts that kept ancestors alive create systematic errors in analysis. Awareness is the first defense.

---

## CRITICAL BIASES FOR POLITICAL ANALYSIS

### 1. CONFIRMATION BIAS
**What it is**: Seeking/favoring evidence that confirms existing beliefs
**In analysis**: Finding Russia connections everywhere because you expect them
**Defense**:
- Actively seek disconfirming evidence
- Ask: "What would change my mind?"
- Have someone argue the opposite

### 2. ANCHORING
**What it is**: Over-weighting first information received
**In analysis**: Initial assessment shapes all subsequent analysis
**Defense**:
- Start fresh with each new evidence
- Explicitly consider: "What if my first take was wrong?"

### 3. ATTRIBUTION ERROR
**What it is**: Attributing others' actions to character, not circumstance
**In analysis**: "They did X because they're corrupt" vs. "They faced Y constraints"
**Defense**:
- Always ask: "What pressures/incentives explain this?"
- Consider structural explanations before personal ones

### 4. AVAILABILITY HEURISTIC
**What it is**: Over-weighting recent/memorable events
**In analysis**: Latest event seems more significant than baseline patterns
**Defense**:
- Maintain historical baselines
- Ask: "Is this actually unusual or just salient?"

### 5. MIRROR IMAGING
**What it is**: Assuming adversaries think/reason like you do
**In analysis**: "They wouldn't do X because it's irrational" (by your standards)
**Defense**:
- Study adversary's stated goals and values
- Accept different rationalities exist

### 6. HINDSIGHT BIAS
**What it is**: Past events seem more predictable than they were
**In analysis**: "It was obvious Russia would invade" (after invasion)
**Defense**:
- Document predictions BEFORE events
- Review past assessments honestly

### 7. GROUPTHINK
**What it is**: Conforming to consensus without independent analysis
**In analysis**: "Everyone says X, so X must be true"
**Defense**:
- Seek contrarian views
- Value dissent
- Red team your conclusions

### 8. MOTIVATED REASONING
**What it is**: Reasoning toward desired conclusions
**In analysis**: Wanting to prove a hypothesis shapes evidence interpretation
**Defense**:
- Identify your preferences before analysis
- Ask: "What would I conclude if I had no stake?"

### 9. PATTERN COMPLETION
**What it is**: Filling gaps with assumed patterns
**In analysis**: "Events A, B, C happened, so D must follow"
**Defense**:
- Note what's actually unknown
- Don't confuse projection with evidence

### 10. RECENCY BIAS
**What it is**: Recent events weighted more than older ones
**In analysis**: Last week's news overshadows last year's context
**Defense**:
- Maintain timelines
- Explicitly include historical context

---

## PRE-ANALYSIS CHECKLIST

Before starting any assessment, answer:

1. **What do I already believe about this?**
   - Note your priors explicitly
   - They will influence analysis whether acknowledged or not

2. **What outcome do I want?**
   - Identify emotional investment
   - Check if analysis serves those preferences

3. **Who is my audience?**
   - Audience expectations shape framing
   - Consider if you're telling them what they want to hear

4. **What would change my mind?**
   - Define falsification criteria upfront
   - If nothing would change your mind, you're not analyzing

5. **What am I not seeing?**
   - Identify blind spots
   - What sources/perspectives am I missing?

---

## PRE-PUBLICATION CHECKLIST

Before publishing any assessment:

- [ ] **Confirmation bias**: Did I seek disconfirming evidence?
- [ ] **Anchoring**: Am I stuck on my first interpretation?
- [ ] **Attribution error**: Did I consider structural explanations?
- [ ] **Availability**: Am I over-weighting recent events?
- [ ] **Mirror imaging**: Did I consider adversary's actual worldview?
- [ ] **Groupthink**: Did I consider contrarian views?
- [ ] **Motivated reasoning**: Would I reach same conclusion with no stake?
- [ ] **Pattern completion**: Am I filling gaps with assumptions?

---

## RED TEAM PROTOCOL

For significant assessments, conduct red team review:

### Step 1: Devil's Advocate
Assign someone (or yourself) to argue the opposite:
- What's the strongest case against this assessment?
- What evidence would support that case?
- How would a defender respond?

### Step 2: Alternative Hypothesis
Generate at least one alternative explanation:
- Same facts, different conclusion
- What would need to be true for alternative to be correct?
- Can you distinguish between hypotheses?

### Step 3: Pre-Mortem
Imagine the assessment is wrong. Work backward:
- What led to the error?
- What evidence was missed?
- What bias was operative?

### Step 4: Outside View
Step outside the specific case:
- How often are similar assessments wrong?
- What's the base rate for this type of claim?
- Am I claiming special insight?

---

## BIAS LOG

When you catch yourself exhibiting bias, log it:

```yaml
- date: 2026-01-20
  bias: confirmation_bias
  context: "Researching Project 2025 connections"
  manifestation: "Only searching for articles that support my thesis"
  correction: "Searched for defenses of Heritage Foundation"
  learning: "Need to build in counter-research step"
```

Reviewing your bias log reveals personal patterns.

---

## INSTITUTIONAL DEFENSES

Beyond individual awareness:

1. **Structured Analytic Techniques**
   - Use frameworks that force consideration of alternatives
   - Devil's advocacy built into process

2. **Diverse Teams**
   - Different backgrounds catch different blindspots
   - Dissent should be valued, not punished

3. **Prediction Tracking**
   - Log predictions with timestamps
   - Review accuracy honestly
   - Hubris dies in sunlight

4. **Revision Culture**
   - Updating views is strength, not weakness
   - Document what changed your mind
   - Celebrate being wrong and admitting it

### 11. UNFALSIFIABILITY TRAP
**What it is**: Accepting claims structured so they cannot be proven wrong
**In analysis**: "SAFE is an investment, not a loan" — reframing debt as investment removes the test (debt has repayment conditions; "investment" has no falsifiable obligation)
**Defense**:
- For every claim, ask: "What evidence would disprove this?"
- If no evidence could disprove it, it is not analysis — it is narrative or marketing
- Flag unfalsifiable claims explicitly: "This claim cannot be tested because [reason]"
- Sagan's Rule 9: claims must be falsifiable to be taken seriously

**Examples**:
- "AGI is coming" — no lab publishes falsifiable criteria they commit to being measured against
- "80-90% will stay in Polish industry" — no data provided, no methodology, no timeline for verification
- "This is an investment, not a loan" — the regulation defines repayment terms; calling it "investment" is rhetorical, not structural

---

### 12. AUTHORITY CREDENTIALISM
**What it is**: Accepting claims because of the claimant's position rather than their evidence
**In analysis**: "The Commissioner says X" taken as evidence for X
**Defense**:
- Sagan's Rule 3: "In science there are no authorities; at most, there are experts"
- Evaluate the evidence, not the title
- Apply actor background checks when authority claims are central to an argument
- Track record matters more than current role

---

## PRE-ANALYSIS CHECKLIST (UPDATED)

Before starting any assessment, answer:

1. **What do I already believe about this?**
   - Note your priors explicitly
   - They will influence analysis whether acknowledged or not

2. **What outcome do I want?**
   - Identify emotional investment
   - Check if analysis serves those preferences

3. **Who is my audience?**
   - Audience expectations shape framing
   - Consider if you're telling them what they want to hear

4. **What would change my mind?**
   - Define falsification criteria upfront
   - If nothing would change your mind, you're not analyzing

5. **What am I not seeing?**
   - Identify blind spots
   - What sources/perspectives am I missing?

6. **Are any claims unfalsifiable?** (NEW)
   - Flag them before they infect the analysis
   - If a core claim can't be tested, the assessment's foundation is weak

7. **Who are the actors and what are their track records?** (NEW)
   - Apply actor background checks for high-stakes assessments
   - See `actor_background_checks.md`

---

## PRE-PUBLICATION CHECKLIST (UPDATED)

Before publishing any assessment:

- [ ] **Confirmation bias**: Did I seek disconfirming evidence?
- [ ] **Anchoring**: Am I stuck on my first interpretation?
- [ ] **Attribution error**: Did I consider structural explanations?
- [ ] **Availability**: Am I over-weighting recent events?
- [ ] **Mirror imaging**: Did I consider adversary's actual worldview?
- [ ] **Groupthink**: Did I consider contrarian views?
- [ ] **Motivated reasoning**: Would I reach same conclusion with no stake?
- [ ] **Pattern completion**: Am I filling gaps with assumptions?
- [ ] **Unfalsifiability**: Are all key claims testable? (NEW)
- [ ] **Authority credentialism**: Am I accepting claims on authority alone? (NEW)
- [ ] **Steel-man test**: Did I build the strongest case against my thesis? (NEW)

---

## PHILOSOPHICAL FOUNDATION

The Zbigniew Protocol's bias defense framework shares intellectual ancestry with Carl Sagan's *Baloney Detection Kit* (1995, *The Demon-Haunted World*). Sagan's nine tools for critical thinking map directly onto our methodology:

| Sagan's Rule | Zbigniew Implementation |
|---|---|
| 1. Independent confirmation | `source_verification.md` — 2+ sources |
| 2. Substantive debate | Red Team Protocol |
| 3. Skepticism of authority | `cui_bono.md` + Authority Credentialism bias |
| 4. Multiple hypotheses | Alternative Explanations section |
| 5. Detachment from ideas | `persona_stability.md` |
| 6. Self-critique | Steel-man the opposition (`reasoning_improvements.md` §1) |
| 7. Quantification | Quantitative ranges (`reasoning_improvements.md` §2) |
| 8. Chain of logic | `validation_gate.md` — every link sourced |
| 9. Falsifiability + Occam's Razor | Falsifiability section + Unfalsifiability Trap bias |

Sagan designed his kit for science. Zbigniew extends it to geopolitics — adding cui bono, pattern mapping, prediction accountability, and actor background checks. Same enemy: confident claims without evidence.

---

## REMEMBER

> "The first principle is that you must not fool yourself —
> and you are the easiest person to fool." - Richard Feynman

> "Extraordinary claims require extraordinary evidence." - Carl Sagan

Every human brain has these bugs.
The best analysts know their bugs and compensate.
